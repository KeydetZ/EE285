{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#import cv2\n",
    "import skimage.morphology as morp\n",
    "from skimage.filters import rank\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import os\n",
    "#import pytorch\n",
    "#import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 7500)\n",
      "(421, 7500)\n",
      "(617, 7500)\n",
      "(617, 1)\n",
      "(617, 7500)\n"
     ]
    }
   ],
   "source": [
    "# obtain data path\n",
    "images_mali = np.load('images_mali.npy')\n",
    "images_benign = np.load('images_benign.npy')\n",
    "#validation_file= \"./NAME\n",
    "#testing_file = \"./NAME\"\n",
    "print(images_mali.shape)\n",
    "print(images_benign.shape)\n",
    "\n",
    "image_original = np.vstack((images_mali,images_benign))\n",
    "#image_sample = random.sample(image_original, 600)\n",
    "#print(type(image_original))\n",
    "#train = image_sample[:400]\n",
    "#test = image_sample[401:]\n",
    "## mali: 0\n",
    "## benign: 1\n",
    "x_label = np.zeros((196,1))\n",
    "y_label = np.ones((421,1))\n",
    "print(train.shape)\n",
    "labels = np.vstack((x_label,y_label))\n",
    "print(labels.shape)\n",
    "print(train.shape)\n",
    "#print(test.shape)\n",
    "#print(images_mali[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of x_training examples:  (150, 7500)\n",
      "Number of y_training examples:  (150, 7500)\n",
      "Number of x_testing examples:  (30, 7500)\n",
      "Number of y_testing examples:  (30, 7500)\n",
      "Number of classes = 2\n"
     ]
    }
   ],
   "source": [
    "# total number: 617\n",
    "# number of training samples: 400\n",
    "# size of x_train = 200\n",
    "# size of y_train = 200\n",
    "# number of testing samples: 217\n",
    "# size of x_test = 108\n",
    "# size of y_test = 109\n",
    "\n",
    "train_percentage = 0.8\n",
    "test_percentage = 0.2\n",
    "\n",
    "# split into x and y for featurs and labels\n",
    "xtrain_idx, ytrain_idx = random.sample(range(int(196*train_percentage)), 150), \\\n",
    "random.sample(range(int(196*train_percentage),int(196*train_percentage)+421), 150)\n",
    "\n",
    "xtest_idx, ytest_idx = random.sample(range(int(196*train_percentage),196), 30), \\\n",
    "random.sample(range(int(196*train_percentage)+421, 617), 30)\n",
    "\n",
    "x_train = image_original[xtrain_idx,:]\n",
    "y_train = image_original[ytrain_idx,:]\n",
    "x_test = image_original[xtest_idx,:]\n",
    "y_test = image_original[ytest_idx,:]\n",
    "x_label = labels[x_idx,:]\n",
    "y_label = labels[y_idx,:]\n",
    "\n",
    "print(\"Number of x_training examples: \", x_train.shape)\n",
    "print(\"Number of y_training examples: \", y_train.shape)\n",
    "\n",
    "print(\"Number of x_testing examples: \", x_test.shape)\n",
    "print(\"Number of y_testing examples: \", y_test.shape)\n",
    "#print(\"Number of testing examples: \", n_test)\n",
    "#print(\"Number of validation examples: \", n_validation)\n",
    "#print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to display the images\n",
    "def list_images(dataset, dataset_y, ylabel=\"\", cmap=None):\n",
    "    \n",
    "    ## change the figure size to reduce features.\n",
    "    #plt.figure(figsize=(15, 16))\n",
    "    plt.figure(figsize = (50, 50))\n",
    "    \n",
    "    # n images to show.\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        indx = random.randint(0, len(dataset))\n",
    "        \n",
    "        #Use gray scale color map if there is only one channel\n",
    "        #cmap = 'gray' if len(dataset[indx].shape) == 2 else cmap\n",
    "        # In this case we prob need to use the RGB images.\n",
    "        #COMPLETE\n",
    "        plt.imshow(dataset[indx], cmap = cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-4b76e22c4160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the sample images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-e694033c6d18>\u001b[0m in \u001b[0;36mlist_images\u001b[0;34m(dataset, dataset_y, ylabel, cmap)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# n images to show.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mindx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the sample images\n",
    "list_images(x_train, y_train)\n",
    "list_images(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-23f36ee3acda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# shuffle the order of the training images to randomize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# shuffle the order of the training images to randomize\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# equalize the RGB images\n",
    "def local_equalize(image):\n",
    "    # change the size of kernel.\n",
    "    kernel = morp.disk(30)\n",
    "    img_local = rank.equalize(image, selem=kernel)\n",
    "    return img_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'COMPLETE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f6de7c43f58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample images after equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mequalized_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_equalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOMPLETE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequalized_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Equalized Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"COMPLETE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Sample images after equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mequalized_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_equalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOMPLETE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequalized_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Equalized Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"COMPLETE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'COMPLETE' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample images after equalization\n",
    "equalized_images = list(map(local_equalize, COMPLETE))\n",
    "list_images(equalized_images, y_train, \"Equalized Image\", \"COMPLETE\")# Sample images after equalization\n",
    "equalized_images = list(map(local_equalize, COMPLETE))\n",
    "list_images(equalized_images, y_train, \"Equalized Image\", \"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the images on a 0 - 1 scale\n",
    "def image_normalize(image):\n",
    "    image = np.divide(image, 255)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ecea4626bb5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sample images after normalizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnormalized_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequalized_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnormalized_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# sample images after normalizing\n",
    "n_training = X_train.shape\n",
    "normalized_images = np.zeros((n_training[0], n_training[1], n_training[2]))\n",
    "for i, img in enumerate(equalized_images):\n",
    "    normalized_images[i] = image_normalize(img)\n",
    "list_images(normalized_images, y_train, \"Normalized Image\", \"COMPLETE\")\n",
    "normalized_images = normalized_images[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes= COMPLETE, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def make_layers(cfg, batch_norm=False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "    cfg = {\n",
    "        'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "    }\n",
    "\n",
    "\n",
    "    def vgg11(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 11-layer model (configuration \"A\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg11_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg13(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 13-layer model (configuration \"B\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['B']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg13_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg16(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['D']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg16_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg19(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 19-layer model (configuration \"E\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['E']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg19_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
