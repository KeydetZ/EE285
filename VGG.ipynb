{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "#import skimage.morphology as morp\n",
    "#from skimage.filters import rank\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import math #test on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utility import *\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images_benign_50.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3de8ddc67930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load data in form of np array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images_benign_50.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# benign:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images_mali_50.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\linin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images_benign_50.npy'"
     ]
    }
   ],
   "source": [
    "#load data in form of np array\n",
    "data_b = np.load('images_benign_50.npy')\n",
    "print(\"# benign:\", data_b.shape)\n",
    "\n",
    "data_m = np.load('images_mali_50.npy')\n",
    "print(\"# malignant:\", data_m.shape) \n",
    "\n",
    "dim = int(math.sqrt(data_b.shape[1] / 3 )) # dimension of the image\n",
    "print(\"dimension of images:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertically stack files\n",
    "data = np.vstack((data_b,data_m))\n",
    "print(\"original data shape:\", data.shape)\n",
    "\n",
    "# create labelset (benign = 1, malignant = 2)\n",
    "label_b = np.ones((data_b.shape[0],1),dtype=np.uint8) # an array of all zeros\n",
    "label_m = np.ones((data_m.shape[0],1),dtype=np.uint8) * 2 # an array of all ones\n",
    "label = np.vstack((label_b,label_m)) # all label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, label_train, data_valid, label_valid, data_test, label_test = train_test_shuffled_separation(data, label, train_percent= 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert label (1/2) to one hot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = label_to_one_hot(label_train)\n",
    "label_valid = label_to_one_hot(label_valid)\n",
    "label_test = label_to_one_hot(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape image arrays to N x size x size x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.reshape((data_train.shape[0], dim, dim, 3))\n",
    "data_valid = data_valid.reshape((data_valid.shape[0], dim, dim, 3))\n",
    "data_test = data_test.reshape((data_test.shape[0], dim, dim, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize image arrays to 0 - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = normalize_data(data_train)\n",
    "data_valid = normalize_data(data_valid)\n",
    "data_test = normalize_data(data_test)\n",
    "print(\"image size:\", data_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display the images\n",
    "def list_images(data, label, ylabel=\"\", cmap=None):\n",
    "    plt.figure(figsize=(15, 16))\n",
    "    \n",
    "    for i in range(6):\n",
    "        plt.subplot(1, 6, i+1)\n",
    "        indx = random.randint(0, len(data))\n",
    "        \n",
    "        #Use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(data[indx].shape) == 2 else cmap\n",
    "        plt.imshow(data[indx], cmap = cmap)\n",
    "        \n",
    "        #plt.xlabel(signs[dataset_y[indx]])\n",
    "        #plt.ylabel(ylabel)\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    #plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sample images\n",
    "list_images(data_train, label_train)\n",
    "list_images(data_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to gray scale\n",
    "def gray_scale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-13 implemented in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13_model = Sequential()\n",
    "\n",
    "#  input dimension is (dim, dim, 3)\n",
    "#  block 1: 2x Conv + Maxpool\n",
    "# 3 -> 32 feature maps\n",
    "VGG13_model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(dim, dim, 3), name='block1_conv1'))\n",
    "VGG13_model.add(Conv2D(32, (3,3), activation='relu', padding='same', name='block1_conv2' ))\n",
    "VGG13_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block1_pool'))\n",
    "VGG13_model.add(Dropout(0.25)) #dropout = 0.25\n",
    "\n",
    "# block 2: 2x Conv + Maxpool\n",
    "# 32 -> 64 feature maps\n",
    "VGG13_model.add(Conv2D(64, (3,3), activation='relu', padding='same', name='block2_conv1'))\n",
    "VGG13_model.add(Conv2D(64, (3,3), activation='relu', padding='same', name='block2_conv2' ))\n",
    "VGG13_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block2_pool'))\n",
    "VGG13_model.add(Dropout(0.25)) #dropout = 0.25\n",
    "\n",
    "# block 3: 2x Conv + Maxpool\n",
    "# 64 -> 128 feature maps\n",
    "VGG13_model.add(Conv2D(128, (3,3), activation='relu', padding='same', name='block3_conv1'))\n",
    "VGG13_model.add(Conv2D(128, (3,3), activation='relu', padding='same', name='block3_conv2' ))\n",
    "VGG13_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block3_pool'))\n",
    "VGG13_model.add(Dropout(0.25)) #dropout = 0.25\n",
    "\n",
    "# block 4: 2x Conv + Maxpool\n",
    "# 128 -> 256 feature maps\n",
    "VGG13_model.add(Conv2D(256, (3,3), activation='relu', padding='same', name='block4_conv1'))\n",
    "VGG13_model.add(Conv2D(256, (3,3), activation='relu', padding='same', name='block4_conv2' ))\n",
    "VGG13_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block4_pool'))\n",
    "VGG13_model.add(Dropout(0.25)) #dropout = 0.25\n",
    "\n",
    "# block 5: 2x Conv + Maxpool\n",
    "# 256 -> 256 feature maps\n",
    "VGG13_model.add(Conv2D(256, (3,3), activation='relu', padding='same', name='block5_conv1'))\n",
    "VGG13_model.add(Conv2D(256, (3,3), activation='relu', padding='same', name='block5_conv2' ))\n",
    "VGG13_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block5_pool'))\n",
    "VGG13_model.add(Dropout(0.25)) #dropout = 0.25\n",
    "\n",
    "# block 6: 3x FC\n",
    "VGG13_model.add(Flatten(name='block6_flatten'))\n",
    "VGG13_model.add(Dense(2048, activation='relu', name='block6_fc1'))\n",
    "VGG13_model.add(Dropout(0.5)) #dropout = 0.5\n",
    "VGG13_model.add(Dense(2048, activation='relu', name='block6_fc2'))\n",
    "VGG13_model.add(Dropout(0.5)) #dropout = 0.5\n",
    "VGG13_model.add(Dense(2, activation='sigmoid', name='predictions')) # output two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the VGG-13 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "# Adam\n",
    "# AdaDelta\n",
    "# SGD\n",
    "SGD = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "VGG13_model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(VGG13_model.layers)):\n",
    "               print(VGG13_model.layers[i].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training VGG-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = VGG13_model.fit(data_train, label_train, batch_size=32, epochs=40, validation_data=(data_valid, label_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate trained VGG-13 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = VGG13_model.evaluate(data_test, label_test, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenet-5 implemented in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LeNet-5](https://cdn-images-1.medium.com/max/1500/1*1TI1aGBZ4dybR6__DI9dzA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5_model = Sequential()\n",
    "\n",
    "#  input dimension is (dim, dim, 3)\n",
    "#  block 1: Conv + Maxpool\n",
    "# 3 -> 6 feature maps\n",
    "LeNet5_model.add(Conv2D(6, (3,3), activation='relu', padding='valid', input_shape=(dim, dim, 3), name='block1_conv1'))\n",
    "LeNet5_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# block 2: Conv + Maxpool\n",
    "# 6 -> 16 feature maps\n",
    "LeNet5_model.add(Conv2D(16, (3,3), activation='relu', padding='same', name='block2_conv1'))\n",
    "LeNet5_model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "# block 3: 3x FC\n",
    "LeNet5_model.add(Flatten(name='block6_flatten'))\n",
    "LeNet5_model.add(Dense(120, activation='relu', name='block3_fc1'))\n",
    "LeNet5_model.add(Dense(84, activation='relu', name='block3_fc2'))\n",
    "LeNet5_model.add(Dense(2, activation='sigmoid', name='predictions')) # output two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile LeNet-5 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "# Adam\n",
    "# AdaDelta\n",
    "# SGD\n",
    "LeNet5_model.compile(optimizer='AdaDelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(LeNet5_model.layers)):\n",
    "               print(LeNet5_model.layers[i].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = LeNet5_model.fit(data_train, label_train, batch_size=32, epochs=40, validation_data=(data_valid, label_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate trained LeNet-5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = LeNet5_model.evaluate(data_test, label_test, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
