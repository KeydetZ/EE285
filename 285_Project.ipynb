{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#import cv2\n",
    "import skimage.morphology as morp\n",
    "from skimage.filters import rank\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import os\n",
    "#import pytorch\n",
    "#import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 7500)\n",
      "(421, 7500)\n",
      "(617, 1)\n"
     ]
    }
   ],
   "source": [
    "# obtain data path\n",
    "images_mali = np.load('images_mali.npy')\n",
    "images_benign = np.load('images_benign.npy')\n",
    "#validation_file= \"./NAME\n",
    "#testing_file = \"./NAME\"\n",
    "print(images_mali.shape)\n",
    "print(images_benign.shape)\n",
    "\n",
    "image_original = np.vstack((images_mali,images_benign))\n",
    "#image_sample = random.sample(image_original, 600)\n",
    "#print(type(image_original))\n",
    "#train = image_sample[:400]\n",
    "#test = image_sample[401:]\n",
    "## mali: 0\n",
    "## benign: 1\n",
    "x_label = np.zeros((196,1))\n",
    "y_label = np.ones((421,1))\n",
    "#print(train.shape)\n",
    "labels = np.vstack((x_label,y_label))\n",
    "print(labels.shape)\n",
    "#print(train.shape)\n",
    "#print(test.shape)\n",
    "#print(images_mali[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of x_training examples:  (150, 7500)\n",
      "Number of y_training examples:  (150, 7500)\n",
      "Number of x_testing examples:  (30, 7500)\n",
      "Number of y_testing examples:  (150, 7500)\n",
      "Number of classes = 2\n"
     ]
    }
   ],
   "source": [
    "# total number: 617\n",
    "# number of training samples: 400\n",
    "# size of x_train = 200\n",
    "# size of y_train = 200\n",
    "# number of testing samples: 217\n",
    "# size of x_test = 108\n",
    "# size of y_test = 109\n",
    "\n",
    "train_percentage = 0.8\n",
    "test_percentage = 0.2\n",
    "\n",
    "size_mali = len(images_mali)\n",
    "size_benign = len(images_benign)\n",
    "\n",
    "# split into x and y for featurs and labels\n",
    "xtrain_idx, ytrain_idx = random.sample(range(int(size_mali*train_percentage)), 150), \\\n",
    "    random.sample(range(size_mali+1,int(size_mali*train_percentage)+size_benign), 150)\n",
    "\n",
    "xtest_idx, ytest_idx = random.sample(range(int(size_mali*test_percentage)), 30), \\\n",
    "random.sample(range(size_mali+1,int(size_mali*train_percentage)+size_benign), 150)\n",
    "\n",
    "x_train = image_original[xtrain_idx,:]\n",
    "y_train = image_original[ytrain_idx,:]\n",
    "x_test = image_original[xtest_idx,:]\n",
    "y_test = image_original[ytest_idx,:]\n",
    "x_label = labels[xtrain_idx,:]\n",
    "y_label = labels[ytrain_idx,:]\n",
    "\n",
    "print(\"Number of x_training examples: \", x_train.shape)\n",
    "print(\"Number of y_training examples: \", y_train.shape)\n",
    "\n",
    "print(\"Number of x_testing examples: \", x_test.shape)\n",
    "print(\"Number of y_testing examples: \", y_test.shape)\n",
    "#print(\"Number of testing examples: \", n_test)\n",
    "#print(\"Number of validation examples: \", n_validation)\n",
    "#print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to display the images\n",
    "def list_images(dataset, dataset_y, ylabel=\"\", cmap=None):\n",
    "    \n",
    "    ## change the figure size to reduce features.\n",
    "    #plt.figure(figsize=(15, 16))\n",
    "    plt.figure(figsize = (50, 50))\n",
    "    num_picture = 10\n",
    "    # n images to show.\n",
    "    for i in range(num_picture):\n",
    "        plt.subplot(1, num_picture, i+1)\n",
    "        idx = random.randint(0, len(dataset))\n",
    "        \n",
    "        #Use gray scale color map if there is only one channel\n",
    "        #cmap = 'gray' if len(dataset[indx].shape) == 2 else cmap\n",
    "        # In this case we prob need to use the RGB images.\n",
    "        #COMPLETE\n",
    "        plt.imshow(dataset[indx], cmap = cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b76e22c4160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the sample images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3b239f3efe49>\u001b[0m in \u001b[0;36mlist_images\u001b[0;34m(dataset, dataset_y, ylabel, cmap)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# In this case we prob need to use the RGB images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#COMPLETE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3081\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5192\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5194\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5195\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    602\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    603\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    }
   ],
   "source": [
    "# plot the sample images\n",
    "list_images(x_train, y_train)\n",
    "list_images(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_images(x):\n",
    "    #range1 = x.max(axis = 0) - x.min(axis = 0)\n",
    "    #print(x)\n",
    "    #print(x.min(axis = 1))\n",
    "    max_value = np.max(x)\n",
    "    min_value = np.min(x)\n",
    "    \n",
    "    normalized = np.interp(x,[min_value,max_value], [-1, 1])\n",
    "    #print(normalized)\n",
    "    return normalized.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 7500)\n",
      "[ 0.12941176  0.60784314  0.49019608  0.06666667  0.62352941  0.41176471\n",
      "  0.41960784 -0.05098039 -0.06666667  0.1372549  -0.41960784  0.22352941\n",
      "  0.4745098   0.10588235  0.31764706  0.25490196  0.33333333  0.3254902\n",
      " -0.4745098  -0.18431373 -0.01960784  0.21568627  0.34117647  0.38039216\n",
      "  0.49019608 -0.56078431  0.12156863  0.2627451  -0.02745098 -0.05098039\n",
      " -0.37254902  0.01960784  0.30980392  0.27058824  0.16862745  0.23921569\n",
      "  0.21568627  0.52156863  0.08235294  0.09803922  0.2         0.31764706\n",
      "  0.6         0.62352941 -0.1372549  -0.21568627  0.16078431  0.05882353\n",
      "  0.23137255  0.10588235  0.12941176  0.8745098   0.85882353  0.3254902\n",
      " -0.36470588  0.11372549 -0.59215686 -0.18431373  0.3254902   0.34901961\n",
      "  0.4745098   0.15294118  0.17647059  0.60784314  0.33333333  0.6\n",
      "  0.9372549   0.35686275  0.42745098  0.18431373  0.3254902   0.41960784\n",
      "  0.48235294  0.41176471  0.3254902   0.05882353  0.12156863  0.36470588\n",
      " -0.4745098   0.5372549   0.70980392 -0.64705882  0.25490196  0.15294118\n",
      "  0.61568627  0.39607843  0.20784314  0.28627451  0.27058824  0.23137255\n",
      "  0.78823529 -0.96078431  0.06666667 -0.52941176  0.38039216  0.36470588\n",
      "  0.51372549  0.61568627  0.42745098  0.37254902 -0.00392157  0.31764706\n",
      "  0.35686275 -0.02745098  0.20784314  0.38823529  0.35686275  0.20784314\n",
      "  0.27058824  0.24705882  0.40392157  0.30980392  0.45098039  0.35686275\n",
      "  0.14509804 -0.69411765 -0.56078431  0.41176471  0.42745098  0.37254902\n",
      "  0.1372549   0.42745098 -0.34117647  0.54509804  0.0745098   0.46666667\n",
      " -0.05882353  0.43529412  0.33333333  0.27843137  0.30980392  0.45882353\n",
      " -0.88235294  0.59215686  0.23137255  0.25490196  0.41176471  0.10588235\n",
      "  0.36470588 -0.04313725 -0.21568627  0.16078431  0.27058824  0.41960784\n",
      " -0.14509804  0.12156863  0.38823529 -0.40392157 -0.02745098  0.16078431]\n",
      "[ 0.0745098  -0.1372549   0.30196078  0.59215686  0.84313725  0.22352941\n",
      "  0.22352941  0.22352941  0.49803922  0.27058824  0.36470588  0.52156863\n",
      "  0.33333333  0.44313725  0.35686275  0.44313725  0.2627451   0.48235294\n",
      "  0.12941176  0.54509804  0.17647059  0.16862745  0.74117647  0.81960784\n",
      "  0.28627451  0.27058824  0.40392157  0.40392157  0.3254902  -0.01960784\n",
      "  0.17647059  0.37254902  0.34901961  0.01176471  0.79607843  0.46666667\n",
      "  0.64705882  0.15294118  0.41176471  0.39607843  0.34117647  0.30196078\n",
      "  0.6627451   0.30980392  0.48235294  0.30196078  0.15294118  0.27058824\n",
      " -0.12941176  0.27843137  0.44313725  0.16862745  0.4745098   0.18431373\n",
      "  0.35686275  0.5372549   0.37254902  0.71764706  0.74901961  0.2\n",
      "  0.50588235  0.31764706 -0.09803922  0.0745098   0.23137255  0.4745098\n",
      "  0.17647059  0.2         0.15294118  0.56862745  0.37254902  0.25490196\n",
      "  0.39607843  0.27843137  0.52941176  0.27843137  0.14509804  0.23921569\n",
      "  0.14509804  0.49019608  1.          0.45882353  0.25490196  0.25490196\n",
      "  0.35686275  0.5372549   0.52156863  0.42745098  0.20784314  0.10588235\n",
      "  0.24705882  0.10588235  0.67058824  0.20784314  0.31764706  0.01176471\n",
      "  0.29411765  0.3254902   0.09019608  0.18431373  0.52941176  0.45882353\n",
      "  0.37254902  0.4745098   0.19215686  0.55294118  0.23137255  0.2627451\n",
      "  0.40392157  0.22352941  0.16862745  0.06666667  0.22352941 -0.10588235\n",
      "  0.50588235  0.45098039  0.41176471  0.55294118  0.4745098   0.14509804\n",
      "  0.45098039  0.31764706  0.22352941  0.67843137  0.46666667 -0.27843137\n",
      "  0.34117647  0.23921569  0.39607843  0.21568627  0.49803922  0.41176471\n",
      "  0.2627451   0.39607843  0.33333333  0.10588235 -0.19215686  0.55294118\n",
      "  0.23921569  0.22352941  0.21568627  0.21568627  0.86666667  0.25490196\n",
      "  0.24705882  0.23921569  0.01176471  0.45882353  0.14509804  0.27843137]\n"
     ]
    }
   ],
   "source": [
    "x_train = normalize_images(x_train)\n",
    "y_train = normalize_images(y_train)\n",
    "print(x_train.shape)\n",
    "print(x_train[:,1])\n",
    "print(y_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label2onehot(lbl):\n",
    "    d = np.zeros((max(lbl) + 1, lbl.size))\n",
    "    #for i in range(lbl.size):\n",
    "        #d[lbl[i], i] = 1\n",
    "    d[lbl, np.arange(0, lbl.size)] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4f6c90531579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel2onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-e3d9940cfba3>\u001b[0m in \u001b[0;36mlabel2onehot\u001b[0;34m(lbl)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlabel2onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#for i in range(lbl.size):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#d[lbl[i], i] = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "\n",
    "x_label = label2onehot(x_label)\n",
    "print(x_label.shape)\n",
    "dtrain[:,42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this part should be changed to sigmoid\n",
    "def softmax(a):\n",
    "    m = a.max(axis = 0)\n",
    "    return np.exp(a - m) / np.sum(np.exp(a - m), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmaxp(a, e):\n",
    "    # given an array whose columns are the vectors a and an array whose columns are vectors e,\n",
    "    # returns an array whose columns are the vectors δ.\n",
    "    g = softmax(a)\n",
    "    return np.multiply(g, e) - np.sum(g * e, axis = 0) * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a7dfd9c75611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# random directions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmaxp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdiff_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-cbab7a7a0939>\u001b[0m in \u001b[0;36msoftmaxp\u001b[0;34m(a, e)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# given an array whose columns are the vectors a and an array whose columns are vectors e,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# returns an array whose columns are the vectors δ.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"
     ]
    }
   ],
   "source": [
    "eps = 1e-6 # finite difference step\n",
    "a = np.random.randn(10, 200) # random inputs\n",
    "e = np.random.randn(10, 200) # random directions\n",
    "print (eps)\n",
    "diff = softmaxp(a, e)\n",
    "print(diff.size)\n",
    "diff_approx = (softmax(a + eps * e) - softmax(a)) / eps\n",
    "print(diff_approx.size)\n",
    "rel_error = np.abs(diff - diff_approx).mean() / np.abs(diff_approx).mean()\n",
    "print(rel_error, 'should be smaller than 1e-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return a * (a > 0)\n",
    "def relup(a,e):\n",
    "    return e * (a > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_shallow(Ni, Nh, No):\n",
    "    # bias 1, return array with size(64,1)\n",
    "    b1 = np.random.randn(Nh, 1) / np.sqrt((Ni+1.)/2.)\n",
    "    \n",
    "    # weight 1, return array with size(64, 784)\n",
    "    W1 = np.random.randn(Nh, Ni) / np.sqrt((Ni+1.)/2.)\n",
    "    \n",
    "    # size(10, 1)\n",
    "    b2 = np.random.randn(No, 1) / np.sqrt((Nh+1.))\n",
    "    \n",
    "    # size(10, 64)\n",
    "    W2 = np.random.randn(No, Nh) / np.sqrt((Nh+1.))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### # of input units, which is 784\n",
    "Ni = xtrain.shape[0]\n",
    "\n",
    "# # of hidden units\n",
    "Nh = 64\n",
    "\n",
    "# # of output units, labels, which is 10\n",
    "No = dtrain.shape[0]\n",
    "\n",
    "# initialize the shallow network with input Ni, Nh, and No.\n",
    "netinit = init_shallow(Ni, Nh, No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop_shallow(x, net):\n",
    "    W1 = net[0]\n",
    "    b1 = net[1]\n",
    "    W2 = net[2]\n",
    "    b2 = net[3]\n",
    "    \n",
    "    a1 = W1.dot(x) + b1\n",
    "    h1 = relu(a1)\n",
    "    a2 = W2.dot(h1) + b2\n",
    "    y = softmax(a2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yinit = forwardprop_shallow(xtrain, netinit)\n",
    "print(yinit[:,1])\n",
    "print(yinit.shape)\n",
    "print(dtrain.shape)\n",
    "print(yinit.size)\n",
    "print(dtrain.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_loss(y, d):\n",
    "    #N = d.shape[0]\n",
    "    loss = -np.sum(d*(np.log(y)))/(d.size)\n",
    "    #print(d)\n",
    "    #print(y)\n",
    "    #print(loss)\n",
    "    return loss\n",
    "    #print(np.sum(d * math.log2(y))\n",
    "    #return - np.sum(d * math.log2(y) + ((1-d) * log2(1 - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(eval_loss(yinit, dtrain), 'should be around .26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_perfs(y, lbl):\n",
    "    pred = onehot2label(y)\n",
    "    # if pred != lbl, return true, which is 1.\n",
    "    # if the statement is false, return 0.\n",
    "    error = np.mean(pred != lbl)\n",
    "    return error\n",
    "    #print(pred)\n",
    "    #print(lbl)\n",
    "    #print(pred[1])\n",
    "    #print(lbl[1])\n",
    "print(eval_perfs(yinit, ltrain))\n",
    "## after taking the mean of the sum of all boolean (true = 1 not match, false = 0 match), we got 0.85, which \n",
    "## means that the dismatched rate is 0.85 = 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_shallow(x, d, net, gamma=.05):\n",
    "    W1 = net[0]\n",
    "    b1 = net[1]\n",
    "    W2 = net[2]\n",
    "    b2 = net[3]\n",
    "    Ni = W1.shape[1]\n",
    "    Nh = W1.shape[0]\n",
    "    No = W2.shape[0]\n",
    "    gamma = gamma / x.shape[1] # normalized by the training dataset size\n",
    "    \n",
    "    # forward prop\n",
    "    a1 = W1.dot(x) + b1\n",
    "    h1 = relu(a1)\n",
    "    a2 = W2.dot(h1) + b2\n",
    "    update_shallow.y = softmax(a2)\n",
    "    \n",
    "    # calculate loss\n",
    "    update_shallow.loss = -np.sum(d*(np.log(update_shallow.y)))/(d.size)\n",
    "    \n",
    "    # Gradient:\n",
    "    #e = eval_loss(update_shallow.y,d)\n",
    "    e = update_shallow.y - d\n",
    "    \n",
    "    # backprop\n",
    "    delta2 = softmaxp(a2, e)\n",
    "    delta1 = relup(a1, W2.T.dot(delta2))\n",
    "    \n",
    "    # gradient update using learning rate (gamma)\n",
    "    W2 = W2 - gamma * delta2.dot(h1.T)\n",
    "    W1 = W1 - gamma * delta1.dot(x.T)\n",
    "    \n",
    "    # update b1 and b2:\n",
    "    b2 = b2 - gamma * delta2.sum(axis = 1).reshape(No, 1)\n",
    "    b1 = b1 - gamma * delta1.sum(axis = 1).reshape(Nh, 1)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop_shallow(x, d, net, T, gamma=.05):\n",
    "    lbl = onehot2label(d)\n",
    "    for t in range(0, T):\n",
    "        # update net\n",
    "        net = update_shallow(x, d, net, gamma)\n",
    "        #print(net[0])\n",
    "        \n",
    "        # display loss and perfs\n",
    "        y = forwardprop_shallow(x, net)\n",
    "        loss = eval_loss(y, d)\n",
    "        perf = eval_perfs(y, lbl)\n",
    "        print(\"iteration\" + str(t+1) + \":\" + \" loss = \" + str(loss) + \" perf = \" + str(perf))\n",
    "        #print(loss)\n",
    "        #print(perf)\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nettrain = backprop_shallow(xtrain, dtrain, netinit, 10, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop_minibatch_shallow(x, d, net, T, B=100, gamma=.05):\n",
    "    N = x.shape[1]\n",
    "    lbl = onehot2label(d)\n",
    "    for t in range(0, T):\n",
    "        for l in range(0, int((N+B-1)/B)):\n",
    "            idx = np.arange(B*l, min(B*(l+1), N))\n",
    "            # update net:\n",
    "            net = update_shallow(x[:,idx], d[:,idx], net, gamma=.05)\n",
    "        y = forwardprop_shallow(x, net)\n",
    "        # display loss and perfs:\n",
    "        loss = eval_loss(y, d)\n",
    "        perf = eval_perfs(y, lbl)\n",
    "        print(\"iteration\" + str(t+1) + \":\" + \" loss = \" + str(loss) + \" perf = \" + str(perf))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netminibatch = backprop_minibatch_shallow(xtrain, dtrain, netinit, 10, B=100, gamma = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the order of the training images to randomize\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# equalize the RGB images\n",
    "def local_equalize(image):\n",
    "    # change the size of kernel.\n",
    "    kernel = morp.disk(30)\n",
    "    img_local = rank.equalize(image, selem=kernel)\n",
    "    return img_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'COMPLETE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f6de7c43f58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample images after equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mequalized_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_equalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOMPLETE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequalized_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Equalized Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"COMPLETE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Sample images after equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mequalized_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_equalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOMPLETE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequalized_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Equalized Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"COMPLETE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'COMPLETE' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample images after equalization\n",
    "equalized_images = list(map(local_equalize, COMPLETE))\n",
    "list_images(equalized_images, y_train, \"Equalized Image\", \"COMPLETE\")# Sample images after equalization\n",
    "equalized_images = list(map(local_equalize, COMPLETE))\n",
    "list_images(equalized_images, y_train, \"Equalized Image\", \"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the images on a 0 - 1 scale\n",
    "def image_normalize(image):\n",
    "    image = np.divide(image, 255)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images after normalizing\n",
    "print(x_train.shape)\n",
    "n_training = x_train.shape\n",
    "print(n_training.shape)\n",
    "normalized_images = np.zeros((n_training[0], n_training[1], n_training[2]))\n",
    "for i, img in enumerate(equalized_images):\n",
    "    normalized_images[i] = image_normalize(img)\n",
    "list_images(normalized_images, y_train, \"Normalized Image\", \"COMPLETE\")\n",
    "normalized_images = normalized_images[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes= COMPLETE, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def make_layers(cfg, batch_norm=False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "    cfg = {\n",
    "        'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "    }\n",
    "\n",
    "\n",
    "    def vgg11(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 11-layer model (configuration \"A\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg11_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg13(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 13-layer model (configuration \"B\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['B']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg13_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg16(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 16-layer model (configuration \"D\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['D']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg16_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg19(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 19-layer model (configuration \"E\")\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['E']), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
    "        return model\n",
    "\n",
    "\n",
    "    def vgg19_bn(pretrained=False, **kwargs):\n",
    "        \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "        Args:\n",
    "            pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            kwargs['init_weights'] = False\n",
    "        model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
    "        if pretrained:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
